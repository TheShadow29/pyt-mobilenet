{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from all_imports import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cifar10 import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mobile_net import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs=64\n",
    "sz=32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class exp_dw_block(nn.Module):\n",
    "    ## Thanks to https://github.com/kuangliu/pytorch-cifar/blob/master/models/mobilenetv2.py\n",
    "    def __init__(self, in_c, out_c, expansion, stride):\n",
    "        super().__init__()\n",
    "        self.stride = stride\n",
    "        exp_out_c = in_c * expansion\n",
    "        \n",
    "        self.ptwise_conv = nn.Conv2d(in_c, exp_out_c, kernel_size=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(exp_out_c)\n",
    "        self.dwise_conv = nn.Conv2d(exp_out_c, exp_out_c, kernel_size=3, \n",
    "                                    groups=exp_out_c, stride=self.stride, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(exp_out_c)\n",
    "        self.lin_conv = nn.Conv2d(exp_out_c, out_c, kernel_size=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(out_c)\n",
    "        \n",
    "        self.res = nn.Sequential()\n",
    "        if self.stride == 1 and in_c != out_c:\n",
    "            self.res = nn.Sequential(nn.Conv2d(in_c, out_c, kernel_size=1, bias=False), \n",
    "                                    nn.BatchNorm2d(out_c))\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        out = F.relu6(self.bn1(self.ptwise_conv(inp)))\n",
    "        out = F.relu6(self.bn2(self.dwise_conv(out)))\n",
    "        out = self.bn3(self.lin_conv(out))\n",
    "        if self.stride == 1:\n",
    "            out = out + self.res(inp)\n",
    "        return out\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mblnetv2(nn.Module):\n",
    "    def __init__(self, block, inc_scale, inc_start, tuple_list, num_classes):\n",
    "        super().__init__()\n",
    "        # assuming tuple list of form:\n",
    "        # expansion, out_planes, num_blocks, stride \n",
    "        self.num_blocks = len(tuple_list)\n",
    "        self.in_planes = inc_start // inc_scale\n",
    "        self.conv1 = nn.Conv2d(3, self.in_planes, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(self.in_planes)\n",
    "        lyrs = []\n",
    "        for expf, inc, nb, strl in tuple_list:\n",
    "            lyrs.append(self._make_layer(block, expf, inc, nb, strl))\n",
    "            \n",
    "        self.lyrs = nn.Sequential(*lyrs)\n",
    "        self.linear = nn.Linear(tuple_list[-1][1], num_classes)\n",
    "        \n",
    "    \n",
    "    def _make_layer(self, block, expf, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block(self.in_planes, planes, expf, stride))\n",
    "            self.in_planes = planes\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, inp):\n",
    "        out = F.relu(self.bn1(self.conv1(inp)))\n",
    "        out = self.lyrs(out)\n",
    "        out = F.adaptive_avg_pool2d(out, 1)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return F.log_softmax(out, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tpl = [(1,  16, 1, 1),\n",
    "       (6,  24, 2, 1),  \n",
    "       (6,  32, 3, 2),\n",
    "       (6,  64, 4, 2),\n",
    "       (6,  96, 3, 1),\n",
    "       (6, 160, 3, 2),\n",
    "       (6, 320, 1, 1)]\n",
    "md_mbl1 = mblnetv2(exp_dw_block, 1, 32,\n",
    "                  tpl,\n",
    "                  num_classes=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(sz, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total parameters in the model :1875162\n"
     ]
    }
   ],
   "source": [
    "learn = ConvLearner.from_model_data(md_mbl1, data)\n",
    "\n",
    "total_model_params(learn.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a7da1778f5847d080e995c75381a595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                   \n",
      "    0      1.189113   1.240661   0.563     \n",
      "    1      0.925725   0.87501    0.6918                      \n",
      "    2      0.763478   0.676452   0.7634                      \n",
      "    3      0.677796   0.617604   0.785                       \n",
      "    4      0.626523   0.572527   0.8065                      \n",
      "    5      0.548613   0.539624   0.8146                      \n",
      "    6      0.509536   0.47996    0.8376                      \n",
      "    7      0.463963   0.4877     0.8352                      \n",
      "    8      0.469171   0.463938   0.8402                      \n",
      "    9      0.415251   0.45054    0.847                       \n",
      "    10     0.401736   0.407783   0.8613                      \n",
      "    11     0.367234   0.426302   0.8548                      \n",
      "    12     0.371078   0.41838    0.8629                      \n",
      "    13     0.349764   0.401366   0.8638                      \n",
      "    14     0.33602    0.36228    0.8766                      \n",
      "    15     0.31557    0.39229    0.8721                      \n",
      "    16     0.324357   0.362141   0.8833                      \n",
      "    17     0.312307   0.371483   0.8753                      \n",
      "    18     0.283638   0.349617   0.883                       \n",
      "    19     0.296591   0.355298   0.8834                      \n",
      "    20     0.280111   0.356223   0.8807                      \n",
      "    21     0.266889   0.360783   0.885                       \n",
      "    22     0.25629    0.326697   0.8938                      \n",
      "    23     0.240324   0.32519    0.8953                      \n",
      "    24     0.239222   0.31548    0.8958                      \n",
      "    25     0.221629   0.312852   0.9006                      \n",
      "    26     0.213286   0.294396   0.9025                      \n",
      "    27     0.211881   0.338609   0.8943                      \n",
      "    28     0.179796   0.291419   0.9063                      \n",
      "    29     0.18016    0.294735   0.9055                      \n",
      "    30     0.171464   0.288461   0.9077                      \n",
      "    31     0.168969   0.298975   0.9092                      \n",
      "    32     0.134193   0.280013   0.9146                      \n",
      "    33     0.156797   0.30634    0.907                       \n",
      "    34     0.123154   0.289883   0.9101                      \n",
      " 44%|████▍     | 343/782 [00:40<00:52,  8.43it/s, loss=0.117] "
     ]
    }
   ],
   "source": [
    "learn.fit(5e-2, 1, cycle_len=50, use_clr_beta=(20, 13.68, 0.95, 0.85), best_save_name='best_mblnetv2_xp_1', metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('best_mblnetv2_xp_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6d15d688e44b928870e01197008ec0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      0.025807   0.284497   0.9314    \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.2845]), 0.9314]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.fit(0, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
